{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitaroktato/deep-learning-exercises/blob/verne-rnn-generator/%20Verne_text_generation_using_RNN..ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text generation in the style of Jules Verne using RNN\n"
      ],
      "metadata": {
        "id": "smCVdpCXifWC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H766SuuViZ7q",
        "outputId": "e14d6b9c-fd8a-4496-9217-8f6dbdb4d0cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.10.12\n",
            "Tensorflow version: 2.17.0\n",
            "Keras version: 3.4.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import platform\n",
        "import time\n",
        "import pathlib\n",
        "import os\n",
        "\n",
        "print('Python version:', platform.python_version())\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('Keras version:', tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the dataset\n",
        "Load the dataset and read the data. Take a look in the text."
      ],
      "metadata": {
        "id": "cen2gAO0i2uA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = './utazas_a_holdra.txt'\n",
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGnb8Nk3i5xY",
        "outputId": "19162988-65dd-4d0b-c341-9cd538639835"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 662630 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First few characters of the text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K_dp5z6jYwx",
        "outputId": "7cc3da4a-1ba4-4c84-d7e6-8ba53087a57b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JULES VERNE\n",
            "UTAZÁS A HOLDBA\n",
            "______\n",
            "UTAZÁS A HOLD KÖRÜL\n",
            "KÉT REGÉNY\n",
            "FORDÍTOTTA: KILÉNYI MÁRIA\n",
            "2\n",
            "TARTALOM\n",
            "UTAZÁS A HOLDBA\n",
            "1. A GUN CLUB\n",
            "2. BARBICANE ELNÖK BEJELENTÉSE\n",
            "3. A BEJELENTÉS HATÁSA\n",
            "4. A CAMBRIDGE-I CSILLAGVIZSGÁLÓ VÁLASZA\n",
            "5. A HOLD REGÉNYE\n",
            "6. A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file. Note, that it contains Hungarian character set.\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "print('{} unique characters'.format(len(vocab)))\n",
        "print('vocab:', vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2O5JXa8_jjZ1",
        "outputId": "0781cecc-b77b-469f-c0f7-9399bb451fc3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118 unique characters\n",
            "vocab: ['\\n', ' ', '!', '%', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '°', 'Á', 'É', 'Í', 'Ó', 'Ö', 'Ú', 'Ü', 'á', 'è', 'é', 'í', 'ó', 'ô', 'ö', 'ú', 'ü', 'Ő', 'ő', 'Ű', 'ű', 'π', '’', '”', '„', '−', '\\uf8eb', '\\uf8ec', '\\uf8ed', '\\uf8ee', '\\uf8ef', '\\uf8f0', '\\uf8f6', '\\uf8f7', '\\uf8f8', '\\uf8f9', '\\uf8fa', '\\uf8fb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process the text\n"
      ],
      "metadata": {
        "id": "F42fiPq2jt0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None)\n",
        "\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "print('{')\n",
        "for char, _ in zip(vocab, range(20)):\n",
        "    print('  {:4s}: {:3d},'.format(repr(char), ids_from_chars(char)))\n",
        "print('  ...\\n}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKlLnwNJkLjJ",
        "outputId": "73f7e063-4214-49c0-804e-dcb53e7f067b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  '\\n':   1,\n",
            "  ' ' :   2,\n",
            "  '!' :   3,\n",
            "  '%' :   4,\n",
            "  \"'\" :   5,\n",
            "  '(' :   6,\n",
            "  ')' :   7,\n",
            "  '*' :   8,\n",
            "  '+' :   9,\n",
            "  ',' :  10,\n",
            "  '-' :  11,\n",
            "  '.' :  12,\n",
            "  '/' :  13,\n",
            "  '0' :  14,\n",
            "  '1' :  15,\n",
            "  '2' :  16,\n",
            "  '3' :  17,\n",
            "  '4' :  18,\n",
            "  '5' :  19,\n",
            "  '6' :  20,\n",
            "  ...\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert chars in text to indices.\n",
        "text_as_int = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "\n",
        "print('text_as_int length: {}'.format(len(text_as_int)))\n",
        "print('{} --> {}'.format(repr(text[:15]), repr(text_as_int[:15].numpy())))"
      ],
      "metadata": {
        "id": "XNLgvvcWs4RF",
        "outputId": "5bc9cbc4-4b27-4549-f5a7-3bffeb29c7b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_as_int length: 662630\n",
            "'JULES VERNE\\nUTA' --> array([37, 48, 39, 32, 46,  2, 49, 32, 45, 41, 32,  1, 48, 47, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create training examples and targets"
      ],
      "metadata": {
        "id": "IQCgjcUhvtOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum length sentence we want for a single input in characters.\n",
        "sequence_length = 100\n",
        "examples_per_epoch = len(text) // (sequence_length + 1)\n",
        "\n",
        "print('examples_per_epoch:', examples_per_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuopxsvYvwWa",
        "outputId": "67f147e0-5404-4a75-f202-3fd6d3820b02"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "examples_per_epoch: 6560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training dataset.\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "\n",
        "for id in ids_dataset.take(10):\n",
        "    print(chars_from_ids(id).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmgnTXnv2Cl",
        "outputId": "3ef6012e-2bb2-44dc-af76-37baca83e154"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J\n",
            "U\n",
            "L\n",
            "E\n",
            "S\n",
            " \n",
            "V\n",
            "E\n",
            "R\n",
            "N\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "\n",
        "# Generate batched sequences out of the char_dataset.\n",
        "sequences = ids_dataset.batch(sequence_length + 1, drop_remainder=True)\n",
        "\n",
        "# Sequences size is the same as examples_per_epoch.\n",
        "print('Sequences count: {}'.format(len(list(sequences.as_numpy_iterator()))));\n",
        "print()\n",
        "\n",
        "# Sequences examples.\n",
        "for item in sequences.take(5):\n",
        "    print(text_from_ids(item).numpy().decode('UTF-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRTHHV3KwThJ",
        "outputId": "7964f66b-e81c-4673-b73d-d3f61434cf77"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequences count: 6560\n",
            "\n",
            "JULES VERNE\n",
            "UTAZÁS A HOLDBA\n",
            "______\n",
            "UTAZÁS A HOLD KÖRÜL\n",
            "KÉT REGÉNY\n",
            "FORDÍTOTTA: KILÉNYI MÁRIA\n",
            "2\n",
            "TARTALO\n",
            "M\n",
            "UTAZÁS A HOLDBA\n",
            "1. A GUN CLUB\n",
            "2. BARBICANE ELNÖK BEJELENTÉSE\n",
            "3. A BEJELENTÉS HATÁSA\n",
            "4. A CAMBRIDGE-\n",
            "I CSILLAGVIZSGÁLÓ VÁLASZA\n",
            "5. A HOLD REGÉNYE\n",
            "6. AMIT MINDEN AMERIKAINAK TUDNIA KELL, ÉS AMIT EGYETLEN \n",
            "AMERIKAINAK SEM\n",
            "SZABAD HINNIE TÖBBÉ\n",
            "7. AZ ÁGYÚGOLYÓ HIMNUSZA\n",
            "8. AZ ÁGYÚ TÖRTÉNETE\n",
            "9. A LŐPORKÉRDÉS\n",
            "10\n",
            ". HUSZONÖTMILLIÓ BARÁT ÉS EGYETLENEGY ELLENSÉG\n",
            "11. FLORIDA ÉS TEXAS\n",
            "12. URBI ET ORBI\n",
            "13. STONE’S HILL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "gSA60YaJz4Wu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChW0Y7i4z8Ob",
        "outputId": "9d7356c8-54bb-472e-edc6-1564d45655db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "# Dataset size is the same as examples_per_epoch.\n",
        "# But each element of a sequence is now has length of `sequence_length`\n",
        "# and not `sequence_length + 1`.\n",
        "print('dataset size: {}'.format(len(list(dataset.as_numpy_iterator()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVWfXsFe0A-_",
        "outputId": "173e3095-5d86-479c-ab5c-4c94cc8b7fef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset size: 6560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print('Input sequence size:', repr(len(input_example.numpy())))\n",
        "    print('Target sequence size:', repr(len(target_example.numpy())))\n",
        "    print()\n",
        "    print('Input:', text_from_ids(input_example).numpy().decode('UTF-8'))\n",
        "    print('Target:', text_from_ids(target_example).numpy().decode('UTF-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24EgwAfo0L9R",
        "outputId": "3e63f541-c175-49e1-e86e-788b7b20c6e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence size: 100\n",
            "Target sequence size: 100\n",
            "\n",
            "Input: JULES VERNE\n",
            "UTAZÁS A HOLDBA\n",
            "______\n",
            "UTAZÁS A HOLD KÖRÜL\n",
            "KÉT REGÉNY\n",
            "FORDÍTOTTA: KILÉNYI MÁRIA\n",
            "2\n",
            "TARTAL\n",
            "Target: ULES VERNE\n",
            "UTAZÁS A HOLDBA\n",
            "______\n",
            "UTAZÁS A HOLD KÖRÜL\n",
            "KÉT REGÉNY\n",
            "FORDÍTOTTA: KILÉNYI MÁRIA\n",
            "2\n",
            "TARTALO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
        "    print('Step {:2d}'.format(i))\n",
        "    print('  input: {} ({:s})'.format(input_idx, chars_from_ids(input_idx).numpy().decode('UTF-8')))\n",
        "    print('  expected output: {} ({:s})'.format(target_idx, chars_from_ids(target_idx).numpy().decode('UTF-8')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIbRGsaM0Zs5",
        "outputId": "c08f7b65-b947-41f2-8b62-922424189beb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step  0\n",
            "  input: 37 (J)\n",
            "  expected output: 48 (U)\n",
            "Step  1\n",
            "  input: 48 (U)\n",
            "  expected output: 39 (L)\n",
            "Step  2\n",
            "  input: 39 (L)\n",
            "  expected output: 32 (E)\n",
            "Step  3\n",
            "  input: 32 (E)\n",
            "  expected output: 46 (S)\n",
            "Step  4\n",
            "  input: 46 (S)\n",
            "  expected output: 2 ( )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create training batches"
      ],
      "metadata": {
        "id": "0svwTVeQMSvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzfN6jY6MW7J",
        "outputId": "61c019ad-af31-4b9c-8be3-7a1f765bdcd0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Batched dataset size: {}'.format(len(list(dataset.as_numpy_iterator()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW3ibDNoMmK_",
        "outputId": "38daf05c-a1ec-4fa1-c5ad-27d66db04ff1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batched dataset size: 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_text, target_text in dataset.take(1):\n",
        "    print('1st batch: input_text:', input_text)\n",
        "    print()\n",
        "    print('1st batch: target_text:', target_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdeCBH2UMpiV",
        "outputId": "f0a924df-d22d-4d2a-dad9-c22930734926"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st batch: input_text: tf.Tensor(\n",
            "[[ 2 62 59 ... 74 63  2]\n",
            " [66 59  2 ...  2 63 66]\n",
            " [58  2 11 ... 72  2 55]\n",
            " ...\n",
            " [62 55 68 ... 67 89 72]\n",
            " [55 74 74 ... 55 66  2]\n",
            " [80 80 89 ... 74 64 75]], shape=(64, 100), dtype=int64)\n",
            "\n",
            "1st batch: target_text: tf.Tensor(\n",
            "[[62 59 66 ... 63  2 63]\n",
            " [59  2 74 ... 63 66 66]\n",
            " [ 2 11 10 ...  2 55  2]\n",
            " ...\n",
            " [55 68 59 ... 89 72  2]\n",
            " [74 74 55 ... 66  2 67]\n",
            " [80 89 65 ... 64 75 65]], shape=(64, 100), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build The Model"
      ],
      "metadata": {
        "id": "U_wmq4O2M_NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's do a quick detour and see how Embeding layer works.\n",
        "# It takes several char indices sequences (batch) as an input.\n",
        "# It encodes every character of every sequence to a vector of tmp_embeding_size length.\n",
        "tmp_vocab_size = 10\n",
        "tmp_embeding_size = 5\n",
        "tmp_input_length = 8\n",
        "tmp_batch_size = 2\n",
        "\n",
        "tmp_model = tf.keras.models.Sequential()\n",
        "tmp_model.add(tf.keras.layers.Embedding(\n",
        "  input_dim=tmp_vocab_size,\n",
        "  output_dim=tmp_embeding_size,\n",
        "  input_length=tmp_input_length\n",
        "))\n",
        "# The model will take as input an integer matrix of size (batch, input_length).\n",
        "# The largest integer (i.e. word index) in the input should be no larger than 9 (tmp_vocab_size).\n",
        "# Now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
        "tmp_input_array = np.random.randint(\n",
        "  low=0,\n",
        "  high=tmp_vocab_size,\n",
        "  size=(tmp_batch_size, tmp_input_length)\n",
        ")\n",
        "tmp_model.compile('rmsprop', 'mse')\n",
        "tmp_output_array = tmp_model.predict(tmp_input_array)\n",
        "\n",
        "print('tmp_input_array shape:', tmp_input_array.shape)\n",
        "print('tmp_input_array:')\n",
        "print(tmp_input_array)\n",
        "print()\n",
        "print('tmp_output_array shape:', tmp_output_array.shape)\n",
        "print('tmp_output_array:')\n",
        "print(tmp_output_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rEHAg9LNB1c",
        "outputId": "a1ea7019-13b7-408a-f1a6-45bd825db65b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
            "tmp_input_array shape: (2, 8)\n",
            "tmp_input_array:\n",
            "[[0 1 3 8 5 7 9 9]\n",
            " [0 2 1 5 2 8 8 5]]\n",
            "\n",
            "tmp_output_array shape: (2, 8, 5)\n",
            "tmp_output_array:\n",
            "[[[-0.04568676 -0.01284541 -0.00155491 -0.02499045  0.00863118]\n",
            "  [ 0.03218542  0.02734811 -0.00964219  0.03639444 -0.01959059]\n",
            "  [ 0.04910115  0.03903227  0.00176507  0.0377253   0.04589237]\n",
            "  [ 0.00459959  0.02586207  0.03284928  0.04320792 -0.01061209]\n",
            "  [-0.03622679 -0.01264     0.02246698  0.02434431 -0.01442967]\n",
            "  [-0.04674475 -0.02353743 -0.03020905  0.00873753 -0.02319526]\n",
            "  [ 0.01862843 -0.04423301 -0.01099458  0.03614916  0.00987977]\n",
            "  [ 0.01862843 -0.04423301 -0.01099458  0.03614916  0.00987977]]\n",
            "\n",
            " [[-0.04568676 -0.01284541 -0.00155491 -0.02499045  0.00863118]\n",
            "  [-0.00576985  0.03029778  0.02817782 -0.04048645 -0.03561816]\n",
            "  [ 0.03218542  0.02734811 -0.00964219  0.03639444 -0.01959059]\n",
            "  [-0.03622679 -0.01264     0.02246698  0.02434431 -0.01442967]\n",
            "  [-0.00576985  0.03029778  0.02817782 -0.04048645 -0.03561816]\n",
            "  [ 0.00459959  0.02586207  0.03284928  0.04320792 -0.01061209]\n",
            "  [ 0.00459959  0.02586207  0.03284928  0.04320792 -0.01061209]\n",
            "  [-0.03622679 -0.01264     0.02246698  0.02434431 -0.01442967]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in chars.\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension.\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units.\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "4DjgSuB7NRkq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Embedding(\n",
        "      input_dim=vocab_size,\n",
        "      output_dim=embedding_dim\n",
        "    ))\n",
        "\n",
        "    model.add(tf.keras.layers.GRU(\n",
        "      units=rnn_units,\n",
        "      return_sequences=True,\n",
        "      stateful=True,\n",
        "      recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
        "    ))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(vocab_size))\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1YWPEdwvNV41"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(vocab_size, embedding_dim, rnn_units, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "umanu3FvNeU3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try the model"
      ],
      "metadata": {
        "id": "K4hG7uBGO8f9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(10):\n",
        "    print(input_example_batch.shape)\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S34880x-Odjb",
        "outputId": "5a9ed68e-bca2-4d65-9723-1dc7a04f73a8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n",
            "(64, 100)\n",
            "(64, 100, 119) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "tC_xiJEtOo7D",
        "outputId": "a6b7c38f-3a1d-49f1-bcf8-f9cc44fe4135"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m30,464\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m3,938,304\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m119\u001b[0m)              │         \u001b[38;5;34m121,975\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,464</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">119</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">121,975</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,090,743\u001b[0m (15.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,090,743</span> (15.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,090,743\u001b[0m (15.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,090,743</span> (15.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Prediction for the 1st letter of the batch 1st sequense:')\n",
        "print(example_batch_predictions[0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQMG94pYO_5U",
        "outputId": "f8d03b07-c5aa-46cb-e1e4-5fbe77740a2a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for the 1st letter of the batch 1st sequense:\n",
            "tf.Tensor(\n",
            "[ 5.53638581e-03  8.46946333e-03  1.10695744e-02  1.46031128e-02\n",
            "  6.61942933e-04 -7.25526176e-03 -6.20857487e-03  1.52903190e-03\n",
            "  1.98550709e-02  8.41939636e-03  9.69224609e-03 -3.03096548e-02\n",
            "  2.22517010e-02  5.41167334e-03  2.92498758e-03  1.21060535e-02\n",
            " -1.26944352e-02  9.51780379e-03 -4.24773665e-03 -1.63760446e-02\n",
            " -6.56844303e-03 -1.39942896e-02 -8.92112032e-03 -4.34356090e-03\n",
            " -7.98467919e-03 -1.01369340e-02  7.54665723e-03 -1.16918329e-02\n",
            "  1.17211053e-02 -5.64851845e-03  1.28133623e-02  5.22732968e-03\n",
            " -7.55425123e-03  7.76874367e-05 -7.47969234e-03  5.24080358e-04\n",
            "  3.46918264e-03 -4.83493600e-03  6.87741861e-03  2.20147846e-03\n",
            "  9.87463817e-03 -3.72948125e-05 -9.80658922e-03 -5.85268997e-03\n",
            " -7.13795191e-04 -5.16781118e-03 -1.16792014e-02 -2.46986654e-02\n",
            "  1.15940999e-02 -3.42167635e-03 -7.79477134e-03 -7.24930968e-03\n",
            " -5.31043764e-03 -8.37845635e-03  9.58454981e-03  9.00609419e-03\n",
            " -5.27997501e-03 -3.54030938e-03  9.24136955e-03 -1.16619770e-03\n",
            "  3.04190908e-04 -2.99376529e-03  7.71743199e-03  7.55818933e-03\n",
            "  6.83226530e-03 -8.45490396e-03 -3.94718070e-03 -7.56095350e-03\n",
            "  1.05427392e-02  5.83334547e-03 -1.77113358e-02 -5.92546444e-03\n",
            " -2.04041749e-02  6.14458276e-03 -3.57235922e-03 -8.43180530e-03\n",
            "  8.02048575e-03  7.18763703e-03 -1.04034161e-02  2.50478592e-02\n",
            " -7.40852207e-03 -7.82536995e-03 -6.27569435e-03 -5.66203520e-03\n",
            " -8.02857615e-03 -2.10274872e-03 -3.26241297e-03 -1.45726334e-02\n",
            " -4.59163683e-03  5.91103407e-03 -9.65525769e-03  1.26126746e-04\n",
            " -6.60164095e-03  1.19244084e-02  3.57526215e-03  9.61485785e-03\n",
            " -6.59575919e-04 -1.57906283e-02  1.70440860e-02  2.82721333e-02\n",
            "  1.83872003e-02 -4.58421651e-03  1.12453112e-02  1.30342757e-02\n",
            "  4.87033511e-03  3.72728705e-03  1.86274201e-03  6.00622036e-04\n",
            "  2.35421630e-03 -9.01489612e-03  5.01996372e-04 -7.07252137e-03\n",
            "  2.74011120e-03 -6.82847947e-03 -2.03097938e-03 -9.79065336e-03\n",
            "  5.09064365e-03 -1.13778678e-03 -5.60743734e-03], shape=(119,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "M9vtg8JMPNiw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# An objective function.\n",
        "# The function is any callable with the signature scalar_loss = fn(y_true, y_pred).\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(\n",
        "      y_true=labels,\n",
        "      y_pred=logits,\n",
        "      from_logits=True\n",
        "    )\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jm_E3PmzPOzh",
        "outputId": "e880f6e2-3e52-4545-8d15-53f9f8b613f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 119)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.7788243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss=loss\n",
        ")"
      ],
      "metadata": {
        "id": "N9fTz4hAPS7O"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure checkpoints"
      ],
      "metadata": {
        "id": "h3CgV5q0PbVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "Rp-r4sTzPd1N"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=40\n",
        "\n",
        "import keras\n",
        "\n",
        "keras.config.disable_traceback_filtering()\n",
        "# keras.backend.set_image_data_format(\"channels_last\")\n",
        "\n",
        "history = model.fit(\n",
        "  x=dataset,\n",
        "  epochs=EPOCHS,\n",
        "  callbacks=[\n",
        "    checkpoint_callback\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJOhfoErPi6k",
        "outputId": "b76b8d75-3934-4e21-acbb-9d2d87e33c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m546s\u001b[0m 5s/step - loss: 3.5625\n",
            "Epoch 2/40\n",
            "\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m47s\u001b[0m 5s/step - loss: 2.3383"
          ]
        }
      ]
    }
  ]
}